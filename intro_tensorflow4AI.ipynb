{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_tensorflow4AI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xie186/Introduction-to-TensorFlow-for-Artificial-Intelligence-Machine-Learning-and-Deep-Learning/blob/master/intro_tensorflow4AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_mIEpvoZOo-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng\n",
        "!echo \"Double check with Python 3\"\n",
        "!python -c \"import pydot\"\n",
        "\n",
        "# Restart runtime to allow Jupyter to know the changes above\n",
        "import os\n",
        "os._exit(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBWuDt2Q9fCZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "i6cyIW7A9kVs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "JfsbGk35OrA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\n"
      ]
    },
    {
      "metadata": {
        "id": "vZFw4BIIOufY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Week1\n"
      ]
    },
    {
      "metadata": {
        "id": "VQwYAAZBO4PN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![image](https://user-images.githubusercontent.com/20909751/55281223-c2d31280-5307-11e9-9324-643319b4ebe8.png)"
      ]
    },
    {
      "metadata": {
        "id": "AAHlM6yjOyyL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Working through ‘Hello World’ in TensorFlow and Python\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pTdZaAgTQ_TD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports\n",
        "\n",
        "Let's start with our imports. Here we are importing TensorFlow and calling it tf for ease of use.\n",
        "\n",
        "We then import a library called numpy, which helps us to represent our data as lists easily and quickly.\n",
        "\n",
        "The framework for defining a neural network as a set of Sequential layers is called keras, so we import that too."
      ]
    },
    {
      "metadata": {
        "id": "Snz4xRxeO192",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zH_CGl1RI0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define and compile the neural network\n",
        "model= tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "\n",
        "## "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSpwWV1-Rz5D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we compile our Neural Network. When we do so, we have to specify 2 functions, a loss and an optimizer.\n",
        "\n",
        "If you've seen lots of math for machine learning, here's where it's usually used, but in this case it's nicely encapsulated in functions for you. But what happens here -- let's explain...\n",
        "\n",
        "We know that in our function, the relationship between the numbers is y=2x-1.\n",
        "\n",
        "When the computer is trying to 'learn' that, it makes a guess...maybe y=10x+10. The LOSS function measures the guessed answers against the known correct answers and measures how well or how badly it did.\n",
        "\n",
        "It then uses the OPTIMIZER function to make another guess. Based on how the loss function went, it will try to minimize the loss. At that point maybe it will come up with somehting like y=5x+5, which, while still pretty bad, is closer to the correct result (i.e. the loss is lower)\n",
        "\n",
        "It will repeat this for the number of EPOCHS which you will see shortly. But first, here's how we tell it to use 'MEAN SQUARED ERROR' for the loss and 'STOCHASTIC GRADIENT DESCENT' for the optimizer. You don't need to understand the math for these yet, but you can see that they work! :)\n",
        "\n",
        "Over time you will learn the different and appropriate loss and optimizer functions for different scenarios."
      ]
    },
    {
      "metadata": {
        "id": "9PuVYeEpR1ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss=\"mean_squared_error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hycvQw2ISGzd",
        "colab_type": "code",
        "outputId": "2b585281-246f-4d8b-e6cf-8e70f2020694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Providing the Data\n",
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "print(xs)\n",
        "print(ys)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.  0.  1.  2.  3.  4.]\n",
            "[-3. -1.  1.  3.  5.  7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aFq1-zTvSiuC",
        "colab_type": "code",
        "outputId": "dba31068-2817-4516-9627-3f79c6472bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "#Training the Neural Network\n",
        "\n",
        "model.fit(xs, ys, epochs=10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 711us/sample - loss: 6.5997e-05\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 795us/sample - loss: 6.4640e-05\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 355us/sample - loss: 6.3313e-05\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 309us/sample - loss: 6.2012e-05\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 302us/sample - loss: 6.0739e-05\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 346us/sample - loss: 5.9491e-05\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 700us/sample - loss: 5.8269e-05\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 362us/sample - loss: 5.7072e-05\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 224us/sample - loss: 5.5900e-05\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 316us/sample - loss: 5.4751e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8aa6bb3d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "pryuS4qeSs-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The process of training the neural network, where it 'learns' the relationship between the Xs and Ys is in the **model.fit**  call. This is where it will go through the loop we spoke about above, making a guess, measuring how good or bad it is (aka the loss), using the opimizer to make another guess etc. It will do it for the number of epochs you specify. When you run this code, you'll see the loss on the right hand side.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Ok, now you have a model that has been trained to learn the relationshop between X and Y. You can use the model.predict method to have it figure out the Y for a previously unknown X. So, for example, if X = 10, what do you think Y will be? Take a guess before you run this code:"
      ]
    },
    {
      "metadata": {
        "id": "d6uIHKzxSzFR",
        "colab_type": "code",
        "outputId": "69f1d0c0-7fdd-429d-c64e-a940547cb4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18.978413]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jVwPFwN-Sy1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You might have thought 19, right? But it ended up being a little under. Why do you think that is?\n",
        "\n",
        "Remember that neural networks deal with probabilities, so given the data that we fed the NN with, it calculated that there is a very high probability that the relationship between X and Y is Y=2X-1, but with only 6 data points we can't know for sure. As a result, the result for 10 is very close to 19, but not necessarily 19.\n",
        "\n",
        "As you work with neural networks, you'll see this pattern recurring. You will almost always deal with probabilities, not certainties, and will do a little bit of coding to figure out what the result is based on the probabilities, particularly when it comes to classification."
      ]
    },
    {
      "metadata": {
        "id": "DS41lKSqZfJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - House Prices - Question"
      ]
    },
    {
      "metadata": {
        "id": "gN-mm4RjZltq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
        "\n",
        "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
        "\n",
        "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
        "\n",
        "Hint: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
      ]
    },
    {
      "metadata": {
        "id": "LRtL_3W8ZkSE",
        "colab_type": "code",
        "outputId": "1f6fc38b-821d-45f1-aa92-84a1bd3a7dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) # Your Code Here\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "xs = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=float)\n",
        "ys = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)\n",
        "model.fit(xs, ys, epochs=10)\n",
        "print(model.predict([7.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 106ms/sample - loss: 0.0983\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 648us/sample - loss: 0.0723\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 407us/sample - loss: 0.0600\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 233us/sample - loss: 0.0542\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0513\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 242us/sample - loss: 0.0497\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 292us/sample - loss: 0.0488\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 279us/sample - loss: 0.0482\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 253us/sample - loss: 0.0478\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 234us/sample - loss: 0.0474\n",
            "[[4.3219185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "io6pLqMVJTPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep neural network"
      ]
    },
    {
      "metadata": {
        "id": "0RywYCpQ9nIx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fasion mnist *data*"
      ]
    },
    {
      "metadata": {
        "id": "I7q3B4BRExsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Deep neural network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "go8reexmCHw7",
        "colab_type": "code",
        "outputId": "ae46f686-4eb0-4795-99b5-c45aa5d0fe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1337
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "plt.imshow(x_train[42])\n",
        "\n",
        "print(y_train[42])\n",
        "print(x_train[42])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187\n",
            "   26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237\n",
            "  255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234\n",
            "  238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237\n",
            "  235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239\n",
            "  238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241\n",
            "  240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241\n",
            "  242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241\n",
            "  244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241\n",
            "  242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242\n",
            "  241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237\n",
            "  236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231\n",
            "  232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230\n",
            "  228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250\n",
            "  251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227\n",
            "  219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184\n",
            "  152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0\n",
            "    0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0\n",
            "    0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgBg8D8oLtVmornzUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lCz_bZMmFO6_",
        "colab_type": "code",
        "outputId": "f22f322f-7ce1-4530-f677-4273239a2ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-vqUoGnCEHjX",
        "colab_type": "code",
        "outputId": "35496c6f-74e0-4757-9cf4-8da71da3df7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "      \n",
        "## Get the mnist data \n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "## In out image data, the values range from 0-255, but in neural network, we better\n",
        "## have normized values (0-1). \n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "## Sequential defines a Sequnce of layes in the neural network\n",
        "model = tf.keras.models.Sequential([ \n",
        "    # Flattern takes the square and turns it into a 1 dim set data\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    # Add a layer of neurons,\n",
        "    # Each layer need an activation function to tell them what to do (many options)\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# In Deep Learning, an epoch is a hyperparameter which is defined before training \n",
        "# a model. One epoch is when an entire dataset is passed both forward and backward\n",
        "# through the neural network only once.\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 13s 216us/sample - loss: 0.4724 - acc: 0.8324\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 207us/sample - loss: 0.3594 - acc: 0.8669\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 205us/sample - loss: 0.3240 - acc: 0.8799\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2992 - acc: 0.8904\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 207us/sample - loss: 0.2807 - acc: 0.8953\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2645 - acc: 0.9007\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2525 - acc: 0.9055\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 13s 209us/sample - loss: 0.2410 - acc: 0.9101\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2308 - acc: 0.9136\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 204us/sample - loss: 0.2235 - acc: 0.9162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc48ef68a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "aPsKUD0HL4So",
        "colab_type": "code",
        "outputId": "a7829b0d-4d94-4d16-da10-3b88353c15d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yp3BbMfDEWL3",
        "colab_type": "code",
        "outputId": "11229e8e-b92a-4d73-a774-f55ca18c4f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 55us/sample - loss: 0.3597 - acc: 0.8762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35968245471715926, 0.8762]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "lK_qkVeaHhtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJ2nMkhYFDTm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Callbacks"
      ]
    },
    {
      "metadata": {
        "id": "FFEnGfVr-hfv",
        "colab_type": "code",
        "outputId": "d046ef7f-ba6f-4ad4-f301-cffa83bfb36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "## Class to handle the callback\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling traning!\")\n",
        "      self.model.stop_trainging = True\n",
        "      \n",
        "## Get the mnist data \n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "## In out image data, the values range from 0-255, but in neural network, we better\n",
        "## have normized values (0-1). \n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "\n",
        "## Sequential defines a Sequnce of layes in the neural network\n",
        "model = tf.keras.models.Sequential([ \n",
        "    # Flattern takes the square and turns it into a 1 dim set data\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    # Add a layer of neurons,\n",
        "    # Each layer need an activation function to tell them what to do (many options)\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# In Deep Learning, an epoch is a hyperparameter which is defined before training \n",
        "# a model. One epoch is when an entire dataset is passed both forward and backward\n",
        "# through the neural network only once.\n",
        "model.fit(x_train, y_train, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.8907 - acc: 0.7052\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "60000/60000 [==============================] - 14s 235us/sample - loss: 0.8898 - acc: 0.7054\n",
            "Epoch 2/5\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.5549 - acc: 0.8018\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.5547 - acc: 0.8019\n",
            "Epoch 3/5\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.4935 - acc: 0.8253\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.4935 - acc: 0.8253\n",
            "Epoch 4/5\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8373\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.4598 - acc: 0.8374\n",
            "Epoch 5/5\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.4390 - acc: 0.8453\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "60000/60000 [==============================] - 14s 227us/sample - loss: 0.4389 - acc: 0.8453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc489b3b898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "DRr3v_D8LiuM",
        "colab_type": "code",
        "outputId": "b0af86ea-e444-4ea8-c449-638bccab76fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSOa7tmSIoOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Enhancing vison with convolutional neural network (CNN)\n"
      ]
    },
    {
      "metadata": {
        "id": "MgSu6bvo285k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementing convolutional layers\n"
      ]
    },
    {
      "metadata": {
        "id": "MoE7blUqIvnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "46929403-a45f-4db3-d6e5-50988a86719a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "## Sequential defines a Sequnce of layes in the neural network\n",
        "modelCNN = tf.keras.models.Sequential([ \n",
        "    \n",
        "    # Here we're specifying the first convolution. We're asking keras to generate\n",
        "    # 64 filters for us. These filters are 3 by 3, their activation is relu, which \n",
        "    # means the negative values will be thrown way, and finally the input shape is \n",
        "    # as before, the 28 by 28. That extra 1 just means that we are tallying using \n",
        "    # a single byte for color depth. As we saw before our image is our gray scale,\n",
        "    # so we just use one byte.\n",
        "    # Out image are grey. \n",
        "    # \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\",\n",
        "                         input_shape=(28,28,1)), \n",
        "    ## MaxPooling layers\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    \n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Flattern takes the square and turns it into a 1 dim set data\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # Add a layer of neurons,\n",
        "    # Each layer need an activation function to tell them what to do (many options)\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gG0nLkpI6z5e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "This next line of code will then create a pooling layer. It's max-pooling because we're going to take the maximum value. We're saying it's a two-by-two pool, so for every four pixels, the biggest one will survive as shown earlier. We then add another convolutional layer, and another max-pooling layer so that the network can learn another set of convolutions on top of the existing one, and then again, pool to reduce the size. So, by the time the image gets to the flatten to go into the dense layers, it's already much smaller. It's being quartered, and then quartered again. So, its content has been greatly simplified, the goal being that the convolutions will filter it to the features that determine the output. A really useful method on the model is the model.summary method. This allows you to inspect the layers of the model, and see the journey of the image through the convolutions, and here is the output. It's a nice table showing us the layers, and some details about them including the output shape. It's important to keep an eye on the output shape column. When you first look at this, it can be a little bit confusing and feel like a bug. After all, isn't the data 28 by 28, so y is the output, 26 by 26. The key to this is remembering that the filter is a three by three filter. Consider what happens when you start scanning through an image starting on the top left. So, for example with this image of the dog on the right, you can see zoomed into the pixels at its top left corner. You can't calculate the filter for the pixel in the top left, because it doesn't have any neighbors above it or to its left. In a similar fashion, the next pixel to the right won't work either because it doesn't have any neighbors above it. So, logically, the first pixel that you can do calculations on is this one, because this one of course has all eight neighbors that a three by three filter needs. This when you think about it, means that you can't use a one pixel margin all around the image, so the output of the convolution will be two pixels smaller on x, and two pixels smaller on y. If your filter is five-by-five for similar reasons, your output will be four smaller on x, and four smaller on y. So, that's y with a three by three filter, our output from the 28 by 28 image, is now 26 by 26, we've removed that one pixel on x and y, and each of the borders. So, next is the first of the max-pooling layers. Now, remember we specified it to be two-by-two, thus turning four pixels into one, and having our x and y. So, now our output gets reduced from 26 by 26, to 13 by 13. The convolutions will then operate on that, and of course, we lose the one pixel margin as before, so we're down to 11 by 11, add another two-by-two max-pooling to have this rounding down, and went down, down to five-by-five images. So, now our dense neural network is the same as before, but it's being fed with five-by-five images instead of 28 by 28 ones. But remember, it's not just one compress five-by-five image instead of the original 28 by 28, there are a number of convolutions per image that we specified, in this case 64. So, there are 64 new images of five-by-five that had been fed in. Flatten that out and you have 25 pixels times 64, which is 1600. So, you can see that the new flattened layer has 1,600 elements in it, as opposed to the 784 that you had previously. This number is impacted by the parameters that you set when defining the convolutional 2D layers. Later when you experiment, you'll see what the impact of setting what other values for the number of convolutions will be, and in particular, you can see what happens when you're feeding less than 784 over all pixels in. Training should be faster, but is there a sweet spot where it's more accurate? Well, let's switch to the workbook, and we can try it out for ourselves."
      ]
    },
    {
      "metadata": {
        "id": "_sWuH9ll6O91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "b6bf606a-eb39-4d28-9c2e-e47cf006bb99"
      },
      "cell_type": "code",
      "source": [
        "modelCNN.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 862,410\n",
            "Trainable params: 862,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bcSNW1te8JOS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feI6JebJ8JtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "91e0126a-e86c-4507-efe1-854658a13d4d"
      },
      "cell_type": "code",
      "source": [
        "modelCNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "modelCNN.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = modelCNN.evaluate(test_images, test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 21s 344us/sample - loss: 0.4143 - acc: 0.8478\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.2768 - acc: 0.8979\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 18s 297us/sample - loss: 0.2319 - acc: 0.9133\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1954 - acc: 0.9264\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 18s 296us/sample - loss: 0.1642 - acc: 0.9370\n",
            "10000/10000 [==============================] - 1s 116us/sample - loss: 0.2675 - acc: 0.9050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-_S3A_ogAecB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a684df13-494d-46f4-b568-7cefc822ae98"
      },
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26754759341478346, 0.905]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "x9TRrOe77o6g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Walking through convolutions\n"
      ]
    },
    {
      "metadata": {
        "id": "iMyWwyzn7mJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}